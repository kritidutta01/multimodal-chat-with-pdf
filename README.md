# ğŸ“š Multimodal Chat with PDFs - Text + Image Understanding

Upload a PDF (reports, research papers, scanned docs, manuals) and **chat with it**.  
Unlike most RAG apps, this one is **multimodal**: it understands both the **text** and the **images/figures/tables** inside the document.  

- Ask about text â†’ retrieves relevant passages.  
- Ask about charts, tables, or diagrams â†’ uses OCR + vision-language models.  
- Get a **combined, context-aware answer**.  

---

## ğŸš€ Features
- ğŸ“„ **PDF Text Understanding** â€“ chunked, embedded, and stored in vector DB.  
- ğŸ–¼ **Image/Diagram Extraction** â€“ OCR + Vision-Language Model (e.g., LLaVA, GPT-4o, Qwen-VL).  
- ğŸ” **Hybrid Retrieval** â€“ retrieves from both text chunks and image captions.  
- ğŸ’¬ **Multimodal Chat UI** â€“ Streamlit/Gradio app for interactive Q&A.  
- ğŸ³ **Deployment Ready** â€“ Docker + HuggingFace Spaces configs included.  
- ğŸ“Š **Evaluation Built-In** â€“ track relevance, latency, and cost.  

---

## ğŸ—ï¸ Architecture

PDF â†’ [Text Extraction] â†’ [Embeddings â†’ Vector DB] â”
[Image Extraction â†’ OCR + Caption + Embeddings] â”˜
Query â†’ Hybrid Retrieval (Text + Image) â†’ LLM â†’ Answer


---

## ğŸ¥ Demo
- [Live Demo on HuggingFace Spaces](#) *(coming soon)*  
- Example Q&A:
  - **Q:** What does Figure 2 in the PDF represent?  
  - **A:** Itâ€™s a bar chart comparing revenue growth across three regions.  

---

## âš™ï¸ Installation

```bash
git clone https://github.com/<your-username>/multimodal-chat-with-pdf.git
cd multimodal-chat-with-pdf
pip install -r requirements.txt

# Run locally
streamlit run src/app.py

---

## ğŸ³ Docker Deployment

You can containerize the app and run it anywhere using Docker.  

### Build the image
```bash
docker build -t multimodal-chat-pdf .




